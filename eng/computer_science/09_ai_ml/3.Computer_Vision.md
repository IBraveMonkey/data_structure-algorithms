# ðŸ‘ï¸ Computer Vision

Computer Vision (CV) allows machines to interpret the visual world. From FaceID to Tesla's autonomous vehicles, CV algorithms are everywhere.

---

## ðŸ“‘ Table of Contents
1. [How does a computer see the world?](#representation)
2. [Tasks and Metrics (IoU, NMS)](#tasks)
3. [Detection: YOLO and Anchor Boxes](#detection)
4. [Segmentation: U-Net and Mask R-CNN](#segmentation)
5. [OCR (Optical Character Recognition)](#ocr)
6. [Popular Architectures](#arch)

---

## ðŸ–¼ï¸ How does a computer see the world?
For a computer, an image is simply a **tensor** (a multi-dimensional array) of numbers.

- **Grayscale**: 1 channel (intensity of gray).
- **RGB**: 3 channels (Red, Green, Blue).
- **RGBA**: 4 channels (+ transparency).

> [!TIP]
> **Augmentation**: To prevent the model from becoming biased toward specific viewpoints, we artificially expand the dataset by rotating images, changing brightness, or adding noise.

---

## ðŸŽ¯ Tasks and Metrics

### Basic Tasks:
1.  **Classification**: "What is in the photo?" (A cat).
2.  **Detection**: "Where and what?" (A cat in a bounding box).
3.  **Segmentation**: "Where is each pixel of the cat?" (A silhouette mask).

### ðŸ“ Detection Metrics

#### 1. IoU (Intersection over Union)
Shows how much the predicted bounding box (BBox) overlaps with the ground truth.
$$IoU = \frac{Area\ of\ Overlap}{Area\ of\ Union}$$
- Ideal = 1.0. Good > 0.5.

#### 2. NMS (Non-Maximum Suppression)
A cleanup algorithm. When the model outputs 10 bounding boxes around the same face, NMS keeps only the one with the highest confidence and removes the others that have a high IoU relative to it.

---

## ðŸš€ Detection: YOLO and Anchor Boxes

**YOLO (You Only Look Once)** is the state-of-the-art for real-time detection.

### Anchor Boxes
Instead of searching for a box of any shape, the model uses a set of "templates" (tall/narrow for a person, square for a sign). The model then simply tunes the deviations from these templates, which significantly speeds up training.

---

## âœ‚ï¸ Segmentation
- **Semantic**: All people are one color.
- **Instance**: Person #1 is red, Person #2 is blue.

**U-Net**: A U-shaped architecture. It first compresses the image (Encoder) to extract meaning and then reconstructs it to the original size (Decoder) to precisely paint the pixels. It is frequently used in medicine.

---

## ðŸ“ OCR (Optical Character Recognition)
The technology for extracting text from images.
- First, the model identifies regions containing text (Detection).
- Next, it decodes the characters (Recognition).
- **Tesseract** and **EasyOCR** are popular libraries.

---

## ðŸ›ï¸ Popular Architectures

| Model | Strong Point | Task |
| :--- | :--- | :--- |
| **ResNet** | Residual connections (Skip-connections). | Classification |
| **EfficientNet** | Optimal scaling. | Mobile devices |
| **YOLOv8** | Incredible speed. | Video detection |
| **ViT** | Global context (Transformers). | Complex scenes |

---

---

> [!IMPORTANT]
> **Transfer Learning** is critical for training vision models today. Always start with `ImageNet` weights unless your task is 100% unique (e.g., images of the Martian surface). ðŸŒŒ
