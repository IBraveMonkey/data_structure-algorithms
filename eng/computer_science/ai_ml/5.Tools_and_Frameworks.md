# ğŸ› ï¸ ML/AI Tools and Frameworks

In the world of AI, tools change every month. Here are the ones that have become industry standards.

---

## ğŸ“‘ Table of Contents
1. [Deep Learning: PyTorch vs TensorFlow](#frameworks)
2. [Classic ML: Scikit-learn and Boostings](#classic)
3. [Optimization and Deployment (ONNX, TensorRT)](#deploy)
4. [MLOps: The Life of a Model in Production](#mlops)
5. [AutoML: For When You're Too Lazy to Write Code](#automl)
6. [GPUs and Clouds](#hardware)

---

## âš”ï¸ PyTorch vs TensorFlow

| Framework | Creator | Pros | Who is it for? |
| :--- | :--- | :--- | :--- |
| **PyTorch** | Meta | Dynamic graph, "pythonic," excellent debugging. | Researchers, startups. |
| **TensorFlow** | Google | Robust deployment, mobile support (TF Lite), TensorBoard. | Large corporations. |

---

## ğŸ“Š Classic ML: Scikit-learn and Boostings
If you have tabular data (Excel, SQL), forget about neural networks in the first stage.

1.  **Scikit-learn**: A universal Swiss Army knife for linear models, forests, and clustering.
2.  **XGBoost / CatBoost / LightGBM**: "Heavy artillery" for tables. These libraries implement gradient boosting and usually win all Kaggle competitions.

---

## âš™ï¸ Optimization and Deployment

### ONNX (Open Neural Network Exchange)
This is a "common language" for models. You can train a model in PyTorch, save it to ONNX, and run it in C++ or a browser without needing PyTorch itself.

### Inference Optimization
- **TensorRT**: A library from NVIDIA that speeds up a trained model by 2-5x on their GPUs.
- **Quantization**: Reducing weight precision (e.g., from 32-bit to 8-bit). The model becomes 4x lighter and faster with minimal loss in quality.

---

## ğŸ—ï¸ MLOps: The Model Is Only the Beginning
Developing a model is only 10% of the work. The remaining 90% is delivering it to the user.

- **MLflow**: Tracking model versions and parameters.
- **DVC**: Git for data (allows versioning of massive files).
- **Bentoml / Ray**: Frameworks for packaging models into APIs (microservices).

---

## ğŸ¤– AutoML
Tools that automatically select the best model and hyperparameters for your data.
- **AutoGluon** (Amazon)
- **H2O Driverless AI**
- **PyCaret** (a wrapper library for quick results)

---

## âš¡ Hardware

- **NVIDIA GPU**: The gold standard. Uses CUDA cores.
- **TPU (Tensor Processing Unit)**: Google's custom chips optimized specifically for TensorFlow/JAX.
- **Apple Neural Engine (M1/M2/M3)**: Accelerators inside Macs, excellent for local inference.

---

---

> [!TIP]
> **Picking a path**: If you're just starting out, go with **PyTorch + Google Colab**. It's the shortest path to getting working neural network code. ğŸğŸ”¥
