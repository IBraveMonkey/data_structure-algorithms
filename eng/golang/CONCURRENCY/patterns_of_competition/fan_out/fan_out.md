### ðŸ“£ Fan-Out Pattern

**Fan-Out** is a pattern where data from a single channel is distributed among multiple handler goroutines (workers). This allows heavy tasks to be performed in parallel, significantly speeding up the processing of large data streams.

---

### ðŸ§  Concept

Imagine a conveyor belt in a factory where parts come off. Instead of one worker doing everything alone, the parts are distributed among several craftsmen, each working independently.

```mermaid
graph LR
    Src[Source Channel] --> Split{Splitter}
    Split --> W1[Worker 1]
    Split --> W2[Worker 2]
    Split --> W3[Worker 3]
```

---

### ðŸ’» Implementation

In this example, one goroutine generates tasks, and three workers process them in parallel.

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

// worker processes tasks from the input channel
// worker Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÐºÐ°Ð½Ð°Ð»Ð°
func worker(id int, input <-chan int, wg *sync.WaitGroup) {
	defer wg.Done()
	for num := range input {
		// Simulating heavy processing
		// Ð˜Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ Ñ‚ÑÐ¶ÐµÐ»Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
		fmt.Printf("Worker %d took task %d\n", id, num)
		time.Sleep(500 * time.Millisecond)
		fmt.Printf("Worker %d finished task %d. Result: %d\n", id, num, num*2)
	}
}

func main() {
	const numWorkers = 3
	tasks := []int{1, 2, 3, 4, 5, 6, 7, 8}

	// Create channels for workers
	// Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ°Ð½Ð°Ð»Ñ‹ Ð´Ð»Ñ Ð²Ð¾Ñ€ÐºÐµÑ€Ð¾Ð²
	inputs := make([]chan int, numWorkers)
	var wg sync.WaitGroup

	// Initialize and start workers
	// Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð²Ð¾Ñ€ÐºÐµÑ€Ñ‹
	for i := 0; i < numWorkers; i++ {
		inputs[i] = make(chan int)
		wg.Add(1)
		go worker(i+1, inputs[i], &wg)
	}

	// Dispatcher
	// Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡ (Dispatcher)
	go func() {
		for i, task := range tasks {
			// Distribute tasks in a round-robin fashion
			// Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¿Ð¾ ÐºÑ€ÑƒÐ³Ñƒ (round-robin)
			inputs[i%numWorkers] <- task
		}

		// Close all channels after distribution
		// Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÑÐµ ÐºÐ°Ð½Ð°Ð»Ñ‹ Ð¿Ð¾ÑÐ»Ðµ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ
		for _, in := range inputs {
			close(in)
		}
	}()

	fmt.Println("Task distribution started...")
	// Ð—Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð¾ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡ Ð¿Ð¾ Ð²Ð¾Ñ€ÐºÐµÑ€Ð°Ð¼...

	wg.Wait()
	fmt.Println("All tasks successfully processed.")
}
```

---

### ðŸ’¡ Key Points

1. **Parallelism**: Allows effective use of all CPU cores for data processing.
2. **Balancing**: With a proper implementation (e.g., using a single shared channel for all workers), tasks are distributed evenly.
3. **Round-Robin**: The example above uses cyclic distribution, but in Go, it's more common for all workers to read from the **same** channel concurrently, which provides automatic load balancing (whoever is free takes the task).

> [!TIP]
> For a simpler implementation, use a shared queue (one channel) that multiple goroutines read from. This avoids the need to create an array of channels and write dispatcher logic.
